{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis with Pandas\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Exploratory Data Analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often with visual methods.\n",
    "\n",
    "Using these exploratory methods will help us into the identification of errors, but also will help us to understand better our data.\n",
    "\n",
    "## What you will learn in this session\n",
    "\n",
    "* Understand the value of visualizing variables\n",
    "* Discover visualization methods\n",
    "* Learn to reshape our data\n",
    "* Discover data properties performing operations over it\n",
    "\n",
    "## Contents\n",
    "* [Cleaning Data](#Cleaning-Data)\n",
    "    * [Technically Correct](#Technically-Correct-Data)\n",
    "    * [Consistency](#Consistency)\n",
    "* [Feature Generation](#Feature-Generation)\n",
    "* [Summarizing Data](#Summarizing-Data)\n",
    "    * [Group By: split-apply-combine](#Group-By:-split-apply-combine)\n",
    "* [Data Visualization](#Data-Visualization)\n",
    "    * [Bar Plot](#Bar-Plot)\n",
    "    * [Histogram](#Histogram)\n",
    "    * [Box Plot](#Box-Plot)\n",
    "    * [Area Plot](#Area-Plot)\n",
    "    * [Scatter Plot](#Scatter-Plot)\n",
    "    * [Hex Bins](#Hex-Bins)\n",
    "    * [Density Plot](#Density-Plot)\n",
    "* [Exercises](#Exercises)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "\n",
    "We will use a dataset as main example during this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the csv\n",
    "airports = pd.read_csv(url,header=None)\n",
    "airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how cool `pandas.read_csv()` is, we don't have to download the data, we can pass a URL and the function itself downloads the data and builds the `DataFrame`.\n",
    "\n",
    "**One first thing to note:** we don't have column names! In this case, whether we go to the source for more information or we guess what each variable is.\n",
    "\n",
    "I've gone through the [OpenFlight page](https://openflights.org/data.html) and I noted down what each variable is.\n",
    "\n",
    "Here you can find an explanation of each variable (**warning: this can change as the source data can change**):\n",
    "\n",
    "1. **Airport ID:** IT is the unique OpenFlights identifier for each airport\n",
    "2. **Name:** Name of airport. Can contain the City name\n",
    "3. **City:** Main city served by airport. Can be spelled differently from Name\n",
    "4. **Country:** Country or territory where airport is located\n",
    "5. **IATA:** 3-letter IATA code. Null if not assigned\n",
    "6. **ICAO:** 4-letter ICAO code. Blank if not assigned\n",
    "7. **Latitude:** Decimal degrees, usually to six significant digits. Negative is South, positive is North\n",
    "8. **Longitude** Decimal degrees, usually to six significant digits. Negative is West, positive is East\n",
    "9. **Altitude:** Altitude in feet\n",
    "10. **Timezone** Hours offset from UTC. Fractional hours are expressed as decimals, eg. India is 5.5\n",
    "11. **DST** Daylight savings time. One of E (Europe), A (US/Canada), S (South America), O (Australia), Z (New Zealand), N (None) or U (Unknown)\n",
    "12. **Tz database** time zone\n",
    "13. **Type:** Type of the airport. Value \"airport\" for air terminals, \"station\" for train stations, \"port\" for ferry terminals and \"unknown\" if not known\n",
    "* **Source:** Source of the data. \"OurAirports\" for data sourced from OurAirports, \"Legacy\" for old data not matched to OurAirports (mostly DAFIF), \"User\" for unverified user contributions. In airports.csv, only source=OurAirports is included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technically Correct Data\n",
    "\n",
    "Before we do anything, let's see if the Dataset is technically correct.\n",
    "\n",
    "##### Assign proper column names to variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To rename `DataFrame` columns we can use `DataFrame.rename()`.\n",
    "* It can be used to rename `index` or/and `columns`. Both are function parameters\n",
    "* To rename we can use function or `dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    0: \"airport_id\",\n",
    "    1: \"name\",\n",
    "    2: \"city\",\n",
    "    3: \"country\",\n",
    "    4: \"IATA\",\n",
    "    5: \"ICAO\",\n",
    "    6: \"lat\",\n",
    "    7: \"lon\",\n",
    "    8: \"alt\",\n",
    "    9: \"tz\",\n",
    "    10: \"DST\",\n",
    "    11: \"tz_db\",\n",
    "    12: \"type\",\n",
    "    13: \"source\"}\n",
    "airports.rename(columns=column_mapping).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.rename(columns=column_mapping).head().rename(columns=lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It can take a subset of columns only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.rename(columns={7: \"latitude\", 8: \"longitude\"}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Returns a new `DataFrame`, use `inplace=True` to overwrite values\n",
    "* Or we can just overwrite the attribute `DataFrame.columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = [\"airport_id\",\"name\",\"city\",\"country\",\"IATA\",\"ICAO\",\"lat\",\"lon\",\"alt\",\"tz\",\"DST\",\"tz_db\",\"type\",\"source\"]\n",
    "airports.columns = h\n",
    "airports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Check dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert `altitude` to metric system\n",
    "The first thing we can do is to convert altitude to meters, so we can explore and analyze this variable easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.alt = airports.alt * 0.3048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check this variable and see its distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.alt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Woah!** -385.876800m under level sea? Let's see who is this. \n",
    "\n",
    "To do such a task I will use `DataFrame.sort_values()`, this method takes a variable name or a list of variables, and returns a `DataFrame` sorted using these values. The parameter `ascending` can be used to sort ascending or descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.loc[airports.alt < 0].sort_values(\"alt\", ascending=True).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Check `NaN`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `city` seems to be the only variable with `NaN`s. Sometimes it is useful to normalize this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just divide the previous operation by number of rows\n",
    "airports.isnull().sum(axis=0) / airports.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see it's just a 6% of the data, but let's see in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.loc[airports.city.isnull(),:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found a pitfall. You see the `\\N`in `IATA`, `tz`, `DST`, `tz_db`? `DataFrame.read_csv()` missed these ones.\n",
    "\n",
    "Let's replace these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "airports.replace(\"\\\\N\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check again `NaN`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.isnull().sum(axis=0) / airports.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the future, you have to know that this can be handled directly in `DataFrame.read_csv()` with the parameters `na_values` and `keep_default_na`:\n",
    "* `na_values`: which values are considered `NaN`. There's already a default list\n",
    "* `keep_default_na`: whether if keep defaults or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports2 = pd.read_csv(url, na_values=\"\\\\N\", keep_default_na=True, names=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports2.isnull().sum(axis=0) / airports.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variable Consistency\n",
    "\n",
    "There is an endless set of tests we can do to check variable consistency. It depends only of our domain knowledge (i.e. what we know about the phenomenon behind the data)\n",
    "\n",
    "**For example** we know that latitude ranges from -90 to 90 and longitude from -180 to 180. It is something we can easily check using `Series.describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.lat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.lon.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we just can check if the statement is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((airports.lat > 90) & (airports.lat < -90)).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((airports.lon > 180) & (airports.lon < -180)).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think in all the \"true things\" we know that must hold, and check if they are true or not in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtls = airports.alt.quantile([.05,.5,.95], interpolation=\"higher\")\n",
    "qtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many of them are below the .05 percentile\n",
    "(airports.alt <= qtls[0.05]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many of them are above the .95 percentile\n",
    "(airports.alt >= qtls[0.95]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation\n",
    "\n",
    "Using our expert knowledge we can also generate new variables. We use variables in the dataset to provide more detail o more dimensions to our data.\n",
    "\n",
    "For example, let's take a look to `tz_db` variable. To do so, I will use `.sample()` it returns a random element of the `Series` or `DataFrame`. We can pass a parameter to select more than one samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.tz_db.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we can extract the continent from it! This way, we are generating a new variable from strings using our sharp eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.tz_db.str.split(\"/\").str[0].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. It is not the continent what we have, but it is an interesting variable. We'll see later what we can do with it.\n",
    "\n",
    "Now, let's add it to our `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports[\"globe_zone\"] = airports.tz_db.str.split(\"/\").str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's generate a new one.\n",
    "\n",
    "We can use latitude to say in which hemisphere each variable is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere = pd.Series((airports[\"lat\"] > 0).map({True: \"north\", False: \"south\"}), dtype=\"category\")\n",
    "hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports[\"hemisphere\"] = hemisphere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also convert a numerical variable into a categorical, so we can group rows using this variable.\n",
    "\n",
    "To do so, we will use the function `pandas.cut()`, this function takes a parameter `bins` in order to indicate how we want to cut the numerical variable, and a parameter to specify the names of the new variable.\n",
    "* `bins` can be an `int` to say in how many equal bins we want to cut the variable, or a `list` of scalars to set the limits of each variable \n",
    "\n",
    "Let's do it with `altitude` and cut it into three bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_label_df = pd.DataFrame({\n",
    "    \"alt\": airports.alt,\n",
    "    \"alt_type\": pd.cut(airports.alt, bins=3, labels=[\"low\", \"med\", \"high\"])\n",
    "})\n",
    "# set it to airports df to use it later\n",
    "airports[\"alt_type\"] = alt_label_df[\"alt_type\"]\n",
    "\n",
    "# get some samples\n",
    "alt_label_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting a lot of lows :-(."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_label_df.alt_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_label_df.alt_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that we have cut all the range into three bins, and... airports are not equally distributed along this range!\n",
    "\n",
    "Airports are normally placed in low places of the Earth... or is it that people lives in low areas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the bins with the parameter `retbins=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, bins = pd.cut(airports.alt, bins=3, labels=[\"low\", \"med\", \"high\"], retbins=True)\n",
    "bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing Data\n",
    "\n",
    "The frequency table is a very good way of summarizing data. We can, for example, check what's the country with more airports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_table = airports.country.value_counts()\n",
    "freq_table.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check specific country position, we have to get the position of an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_table.index.get_loc(\"Spain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_table.iloc[21-3:21+3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we want to group data?\n",
    "\n",
    "For example to know what's the country with more airports per continent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for globe_zone in airports.globe_zone.unique():\n",
    "    print(globe_zone)\n",
    "    display(airports.loc[airports.globe_zone == globe_zone,\"country\"].value_counts().head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this approach has some problems:\n",
    "* We iterate over `DataFrames` which is not elegant\n",
    "* For each operation we want to make, we have to redo or modify this iteration\n",
    "* The result is not a `pandas` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group By: split-apply-combine\n",
    "(*from: https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html*)\n",
    "\n",
    "By \"group by\" we are referring to a process involving one or more of the following steps:\n",
    "\n",
    "* **Splitting** the data into groups based on some criteria.\n",
    "    * Like selecting continents\n",
    "* **Applying** a function to each group independently.\n",
    "    * Like `value_counts` and `head`\n",
    "* **Combining** the results into a data structure.\n",
    "    * We haven't\n",
    "    \n",
    "Out of these, the split step is the most straightforward. \n",
    "\n",
    "In fact, in many situations we may wish to split the data set into groups and do something with those groups. \n",
    "\n",
    "In the **apply** step, we might wish to do one of the following:\n",
    "\n",
    "**Aggregation:** compute a summary statistic (or statistics) for each group. Some examples:\n",
    "* Compute group sums or means.\n",
    "* Compute group sizes / counts.\n",
    "\n",
    "**Transformation:** perform some group-specific computations and return a like-indexed object. Some examples:\n",
    "* Standardize data (zscore) within a group.\n",
    "* Filling NAs within groups with a value derived from each group.\n",
    "\n",
    "**Filtration:** discard some groups, according to a group-wise computation that evaluates True or False. Some examples:\n",
    "* Discard data that belongs to groups with only a few members.\n",
    "* Filter out data based on the group sum or mean.\n",
    "\n",
    "**Some combination of the above:** GroupBy will examine the results of the apply step and try to return a sensibly combined result if it does not fit into either of the above two categories.\n",
    "\n",
    "Since the set of object instance methods on pandas data structures are generally rich and expressive, we often simply want to invoke, say, a DataFrame function on each group. \n",
    "\n",
    "The name GroupBy should be quite familiar to those who have used a SQL-based tool (or `itertools`), in which you can write code like:\n",
    "```sql\n",
    "SELECT Column1, Column2, mean(Column3), sum(Column4)\n",
    "FROM SomeTable\n",
    "GROUP BY Column1, Column2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting an object into groups\n",
    "\n",
    "`pandas` objects can be split on **any of their axes**. \n",
    "\n",
    "The abstract definition of grouping is **to provide a mapping of labels to group names**. \n",
    "\n",
    "To create a GroupBy object (more on what the GroupBy object is later), you may do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airp_group = airports.groupby([\"globe_zone\",\"alt_type\"])\n",
    "airp_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the object returned is not a `DataFrame` and it can't be visualized.\n",
    "\n",
    "The mapping (group names -> labels) can be specified many different ways.\n",
    "\n",
    "We generally will specify which columns will be used to map the labels (like in the previous example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GroupBy object attributes\n",
    "\n",
    "The groups attribute is a `dict` whose keys are the computed unique groups and corresponding values being the axis labels belonging to each group. \n",
    "\n",
    "In the above example we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airp_group.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(airp_group.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataFrame column selection in GroupBy\n",
    "\n",
    "Once you have created the GroupBy object from a DataFrame, you might want to do something different for each of the columns. \n",
    "\n",
    "Thus, using `[]` similar to getting a column from a DataFrame, you can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airp_group[\"city\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note again that this slice does not return a `Series` but a `SeriesGroupBy`.\n",
    "\n",
    "The difference between a `GroupBy` object and `SeriesGroupBy` is that the later one only has values of a single column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airp_group[\"city\"].groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting a group\n",
    "\n",
    "A single group can be selected using `get_group()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airp_group.get_group((\"Europe\", \"low\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the difference applying it to a `SeriesGroupBy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airp_group[\"city\"].get_group((\"Europe\", \"low\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregation\n",
    "\n",
    "Once the GroupBy object has been created, several methods are available to perform a computation on the grouped data. \n",
    "\n",
    "**The basic idea is:** perform an operation over labels and return a single value per group name-column.\n",
    "\n",
    "An obvious one is aggregation via the `aggregate()` or equivalently `agg()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airp_group[\"alt\"].agg(np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another simple aggregation example is to compute the size of each group. \n",
    "\n",
    "This is included in `GroupBy` as the size method. \n",
    "\n",
    "It returns a `Series` whose index are the group names and whose values are the sizes of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airp_group.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airp_group.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtration\n",
    "\n",
    "The filter method returns a subset of the original object. \n",
    "\n",
    "Suppose we want to take only elements that are all from hemisphere north"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airp_group.filter(lambda x: (x[\"hemisphere\"] == \"north\").all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other useful methods, as for example `.first()`, to filter top values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airp_group.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airp_group[\"alt\"].agg({\"max\":np.max,\"min\":np.min,\"mean\":np.mean}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we also saw how to pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.groupby(\"hemisphere\").alt.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "One of the most useful tools for exploring data and presenting results is through visual representations or plots.\n",
    "\n",
    "`pandas` has a `plot` method on `Series` and `DataFrame` which is just a simple wrapper around `matplotlib.pyplot.plot()`.\n",
    "\n",
    "There's more links among data visualization libraries. Check the `pandas` visualization ecosystem in [`pandas` docs](https://pandas.pydata.org/pandas-docs/stable/ecosystem.html#ecosystem-visualization).\n",
    "\n",
    "As we said, `plot` method wraps `matplotlib.pyplot.plot()` so we can configure some of the `matplotlib.pyplot` properties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is not needed, but will make visualizations prettier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = [10, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a constant variable, during this first part we will plot simple functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame(np.ones(100),columns=[\"y\"])\n",
    "my_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the `y` variable is as easy as this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `plot()` wrapper has picked automatically `y` variable as y-axis and the `index` as x-axis.\n",
    "\n",
    "Now let's create a new variable `z` which is the cumulative sum (`Series.cumsum()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df[\"z\"] = my_df.y.cumsum()\n",
    "my_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that again, `plot()` picks variables `y` and `z` as y-axis and `series` as x-axis. \n",
    "\n",
    "We specify and change this behaviour using `x` and `y` parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.plot(y=\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.plot(x=\"y\", y=\"z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play plotting different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.y = my_df.z ** 2\n",
    "my_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.z = np.log(my_df.y)\n",
    "my_df.z.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to split the visualization into different subplots.\n",
    "\n",
    "To do so, we have to use `matplotlib.pyplot`. Basically we use `plt.sublots` specifying the grid size we want to use. `plt.sublots` method returns:\n",
    "\n",
    "\n",
    "* `fig` : `Figure`. We can use this object to control layout attributes such as axes names, legends, etc.\n",
    "* `ax` : `axes.Axes` object or array of `Axes` objects. `ax` can be either a single `Axes` object or an array of `Axes` objects if more than one subplot was created. We will use this object to plot data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "# we use the ax parameter to specify where to plot the data\n",
    "my_df.plot(y=\"z\", ax=axes[0])\n",
    "my_df.plot(y=\"y\", ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`plot` can take a parameter `kind` to plot different plot types:\n",
    "* `bar` or `barh` for [bar plots](##Bar-Plot)\n",
    "* `hist` for [histogram](#Histogram)\n",
    "* `box` for [boxplot](#Box-Plot)\n",
    "* `kde` or `density` for [density plots](#Density-Plot)\n",
    "* `area` for [area plots](#Area-Plot)\n",
    "* `scatter` for [scatter plots](#Scatter-Plot)\n",
    "* `hexbin` for [hexagonal bin plots](#Hex-Bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Plot\n",
    "\n",
    "A bar plot is used to visualize qualitative variables vs quantitative variables. For example, we can plot `globe_zone` vs `airport number`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.groupby(\"globe_zone\").size().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good, however, this plot is not very useful for comparing continents (not sorted!).\n",
    "\n",
    "No problem at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = airports.groupby(\"globe_zone\").size().map(lambda x: np.log(x)).sort_values().plot.bar()\n",
    "\n",
    "new_ytick = [\"$10^{}$\".format(int(i)) for i in ax.get_yticks()]\n",
    "_ = ax.set_yticklabels(new_ytick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiple Bars\n",
    "\n",
    "We can visualize multiple quantitative variables in the same plot. Let's do this visualizing a `GroupBy` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.\\\n",
    "    groupby(\"globe_zone\").\\\n",
    "    alt.\\\n",
    "    agg({\"max\":np.max,\"min\":np.min,\"mean\":np.mean}).\\\n",
    "    plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = airports.\\\n",
    "    groupby(\"globe_zone\")[\"alt\"].\\\n",
    "    agg({\"max\":np.max,\"min\": np.min,\"mean\": np.mean}).\\\n",
    "    sort_values(by=\"max\").\\\n",
    "    plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth sorting it, note that now you can sort the plot using different aggregated variables.\n",
    "\n",
    "Bar plots allow plotting several variables into a single bar, this parameter is `stacked` and its default value is `False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = airports.\\\n",
    "    groupby(\"globe_zone\")[\"alt\"].\\\n",
    "    agg({\"max\":np.max,\"min\": np.min,\"mean\": np.mean}).\\\n",
    "    sort_values(by=\"max\").\\\n",
    "    plot(kind=\"bar\", stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Horizontal bars\n",
    "\n",
    "x-axis and y-axis can be interchanged, leading an horizontal bar plot. It can be done passing as parameter `barh` instead of `bar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.\\\n",
    "    groupby(\"globe_zone\").\\\n",
    "    alt.\\\n",
    "    agg({\"max\":np.max,\"min\":np.min,\"mean\":np.mean}).\\\n",
    "    sort_values(\"max\").\\\n",
    "    plot(kind=\"barh\", stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram\n",
    "\n",
    "A histogram is an accurate representation of the distribution of numerical data. With this plot type we can see the distribution of a numerical variable.\n",
    "\n",
    "Basically it represents the frequency in the variable intervals. These intervals are named `bins`and we have to specify how many of them we want to see. The default values is `bins=10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.alt.plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.loc[:,[\"alt\"]].plot(kind=\"hist\", bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.loc[:,[\"lat\"]].plot(kind=\"hist\",bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.loc[:,[\"lon\"]].plot(kind=\"hist\",bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plot\n",
    "\n",
    "We have already seen Box Plots. This kind of plot shows quartiles, whiskers and outliers.\n",
    "\n",
    "Note that box plot is a numerical variable plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.alt.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.pivot(columns=\"globe_zone\").alt.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.pivot(columns=\"globe_zone\").alt.plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Plot\n",
    "\n",
    "Area Plots show a variable (always grows) as a filled area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_airp = airports[airports.country==\"Spain\"].alt\n",
    "sp_airp.index = range(sp_airp.size)\n",
    "sp_airp.plot.area()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we sort the values, we can have a look at the variable distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_airp = airports[airports.country==\"Spain\"].alt\n",
    "sp_airp = sp_airp.sort_values()\n",
    "sp_airp.index = range(sp_airp.size)\n",
    "sp_airp.plot.area()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plot\n",
    "\n",
    "Scatter plots show the relation between two variables as points.\n",
    "\n",
    "For example, imagine you have the following variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"name\": [\"human\", \"spider\", \"snail\", \"fly\", \"cyclop\"],\n",
    "    \"number_eyes\": [2, 8, 2, 2, 1],\n",
    "    \"number_legs\": [2, 8, 0, 6, 0]\n",
    "}).plot.scatter(x=\"number_eyes\", y=\"number_legs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens if we plot lat vs. lon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "airports.plot.scatter(y=\"lat\",x=\"lon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a third variable, to make the mark change in a shade of color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.plot.scatter(y=\"lat\",x=\"lon\",c=\"alt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or make it bigger as the altitude is bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.plot.scatter(y=\"lat\",x=\"lon\",s=airports[\"alt\"]/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hex Bins\n",
    "\n",
    "There are other ways of representing relations between two or more variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.plot.hexbin(x=\"lon\", y=\"lat\", C=\"alt\", gridsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density Plot\n",
    "\n",
    "Finally, similar to histograms, with kernel density estimator plots we can see a distribution of a numerical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.alt.plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.lat.plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.lon.plot.kde()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "The exercises will be based over 2018 New Coder Survey, which is a survey answered by 15000 coders and contains 46 questions (each question is a variable).\n",
    "\n",
    "Data is available https://raw.githubusercontent.com/freeCodeCamp/2018-new-coder-survey/master/raw-data/2018-new-coder-survey.csv\n",
    "\n",
    "Over these dataset, please answer the following questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show in a barplot top 10 nationalities with more responents**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show in a barplot top 10 countries with more respondents**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do an outlier analysis of the ages. How many outliers there are using box-and whiskers? How many using 5%-95%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Draw a box plot for ages in USA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show the average Age per country. Which is the country with older respondants? Which the country with younger?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do an outlier analysis of the incomes. How many outliers there are using box-and whiskers? How many using 5%-95%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Draw a box plot for incomes in Spain**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which is the mean income? And the mean income per age? Plot an area plot. Split Incomes into 4 ranges and plot a barplot for top ten respondant countries with 4 bars counting how many people is in each range**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do a density plot with incomes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do an histogram with incomes. Select a right number of bins so density plot and histogram are similar**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do an scatter plot, ploting age and commut time with a third variable which is income**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
